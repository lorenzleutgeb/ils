\documentclass{llncs}

% A. Objectives
%    1. You should apply one of the techniques studied in the course to
%       solve this problem.
%    2. Devise and perform an empirical evaluation of your system.
%    3. Report your work.
%    4. All your documentation and source code should be available on your GitLab
%       project repository, as well as tasks and milestones. This will be part of
%       the evaluation.
%
% B. Deliverables
%    1. Progress report (by the end of May) describing
%     - selected approach and
%     - general project work plan
%     - group presentation of the report
%    2. Project report
%     - description of the problem
%     - updated material from the progress report
%     - description of your approach
%     - description of the software: installation, requirements and usage notes
%     - empirical evaluation
%    3. Software
%     - application and required libraries/software
%     - brief installation notes (README file)
%    4. Final Presentation
%     - description of your approach
%     - strengths and weaknesses
%     - empirical evaluation
%     - contribution of team members
%
% C. Timeline
%    1. 2018-05-30 Progress report and presentation
%    2. 2018-06-18 Software deliverable and final report
%    3. 2018-06-22 Final Presentation and Demo

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{csquotes}

\newcommand{\htw}{\emph{Hunt the Wumpus }}

\title{Hakuna Matata: A Logic-Based Agent for the \htw Game}
\subtitle{Project Report}
\author{Team White\\[2mm]Filippo~De~Bortoli \and Aneta~Koleva \and Lorenz~Leutgeb}
\institute{Free University of Bozen-Bolzano\\[3mm] \texttt{\{\href{mailto:filippo.debortoli@stud-inf.unibz.it}{filippo.debortoli},\href{mailto:aneta.koleva@stud-inf.unibz.it}{aneta.koleva},\href{mailto:lorenz.leutgeb@stud-inf.unibz.it}{lorenz.leutgeb}\}\newline @stud-inf.unibz.it}}

\begin{document}

\maketitle

\begin{abstract}
  The assigned task is to develop an intelligent agent that plays the \htw game, by using a logic-based approach in its implementation.
  In order to complete a run of the game, this agent has to be able to face several challenges, like the incompleteness of the available information about the state of the world or the search for the best strategy to employ.
  The chosen approach is to develop a hybrid agent that relies on an ASP core to actuate its strategy and on graph-theory techniques to obtain additional insights on how to proceed in the exploration of a dungeon.
  To assess the performance of our agent, we implemented an omniscient agent that obtains an optimal score for a given dungeon and we ranked our agent against it.
  In this report, we introduce our solution to this task, by detailing the architecture of the agent and describing the chosen strategy, the heuristics and the obtained results.
\end{abstract}

\section{Problem Statement}
%TODO Define what \htw is, all its rules and constraints.
%TODO Mention that it is also an example in the standard textbook AIMA and thus suited as an exercise in logic-based AI.

\htw is a single player, old computer game which was first released back in 1975. The game is played in the wumpus world(a cave) which is represented as a grid (default size 4x4) and in this world there are few challenges for the player. Each cell on the grid is a room which is connected by passageways with its orthogonally adjacent cell and in one of these cells there is wumpus, a beast that eats the player if he enters the room. The player has only one arrow, that's one opportunity for shooting the wumpus. In addition, some of the rooms are bottomless pits and if the player wanders in these rooms it will stay trapped. The main goal of the player is while facing these challenges, to find the hidden gold and leave the cave alive. At the beginning of the game, the player is always positioned on cell [1,1], facing to the right and has 0 points. From here it can use three moves : \textit{Forward, TurnLeft, TurnRight} for discovering its environment and three actions \textit{Shoot, Grab} and \textit{ Climb} for shooting the arrow, grabbing the gold and climbing out of the cave respectively. For each of the moves and actions the player loses 1 point and 10 points when using the arrow. When eaten by the wumpus or trapped in pit, loses 1000 points, and for climbing out of the cave with the gold gains 1000 points. Whenever the player goes to a new cell, it has five sensors that give information about:
\begin{description}
	\item [$\bullet$] Stench - whether the Wumpus is in adjacent cell 
	\item [$\bullet$] Breeze - whether there is a pit in adjacent cell	
	\item [$\bullet$] Glitter - when the gold is in the current cell
	\item [$\bullet$] Bump - whether the player has hit a border
	\item [$\bullet$] Scream- whether the Wumpus is hit by the arrow 
\end{description}
The locations of the gold and the wumpus are chosen randomly with uniform distribution in each cell other then the start. Additionally each cell can be a pit with probability 0.2.

In the book Artificial Intelligence: A Modern Approach, the game is used as an example for representing knowledge-based agents. The environment which represents the Wumpus World is is described as discrete, static, single-agent and partly-observable. For an agent in such environment the main challenge is its initial ignorance of the configuration of the world and using logical reasoning can be helpful for solving this. 



\section{Approach}
% This should be a high-level section that does not really talk too much
% about code (for that we have the "Implementation" section), but instead
% about the general approach.
\subsection{ASP technique}
For the purpose of this project, we decided to implement an intelligent agent that plays the wumpus game using ASP technique in combination with graph-theory techniques to explore the search space and find its best strategy for finishing the game with maximum points. The environment in which the agent is playing is discrete and static, since the wumpus, the gold and the pits are all fixed. The agent's initial knowledge base contains the rules of the game without specifying the size of the grid. The size is discovered by the agent when it hits a border and the 'Bump' percept is on, after which the agent knows how big the search space it is. In order to be able to find the best strategy, the agent first needs to acquire certain knowledge about the search space and to be able to reason wrt this knowledge. The facts and rules in the knowledge base are specified as ASP rules and DVL solver is used for grounding and solving. One of the advantages of ASP is the fact that it uses non-monotonic reasoning and closed world assumption which allow the agent to correctly derive what is logically right from it's knowledge base. Moreover DLV is able to process incomplete knowledge which the agent has while overcoming its initial ignorance with logical reasoning. 

%TODO Justify why we chose ASP (non-monotonic reasoning, fits nicely with incomplete knowledge), previous experience with it, easier to write high-level logic thanks to grounding. 
% maybe mention that we can write strong constraints, not sure if still have that

\subsection{A* search algorithm}
For better exploration of the world, we build a graph that represents reachability (with cost) for all cells. Then we use \textit{Manhattan distance} as a cost function for calculating the cost for moving from a cell to a cell. We also consider the rotation cost  when the agent reasons about the number of moves it needs to make in order to move from a cell to another cell. To calculate this cost, first the cost of all turns on the way from current cell to a destination cell is calculated and to this is added the cost of departing the current cell (whether the agent needs to turn before leaving). For calculating the minimal cost of reaching the destination cell we use \textit{A* search algorithm} : \(f(n) = g(n) + h(n)\). \
In order to efficiently use this algorithm next and goal cell must be known. 
First the goal cell is calculated and based on this result, the next cell is decided.  The choice of a goal cell depends on the current mode of the agent which are explained below. If it's in mode \textit{explore}, goal is a reachable cell which is safe and hasn't been explored yet. If the agent's mode is \textit{kill}, then the goal is a cell which is safe and from which the wumpus can be shot.   
In our program \(g(n)\) represents the cost of the path from the current cell to the next cell \(n\), and \(h(n)\) represents the heuristic estimated cost of the cheapest path from cell \(n\) to the goal cell. 

%TODO How does our agent explore the world (A*-search)
%not sure if here should be explained the purpose of pathTurnCost,
%departureTurnCost and rotCost or leave that for implementation

\subsection{Different modes}
In order to simplify the implementation of the agent and the way it choses its next action we introduce four different modes of playing in which the agent can be at any time. This helps to abstract and in different modes enable and disable different possible actions. It also made it easier for developing the code. 
While playing, our agent can be in exactly one from four available modes. 
\paragraph{Explore} The agent is in this mode until it discovers the gold or there are more cells which should be explored. These are cells which are known to be reachable, safe and not yet explored. 

\paragraph{Grab} Once the agent is in the cell where can perceive glitter, its next action is to grab the gold and in this moment is in mode \textit{grab}. 

\paragraph{Kill} In order for the agent to deduce that is in mode \textit{kill} few conditions need to be satisfied. First it should not be in mode grab or explore and the gold is still not grabbed. Next it should be able to attack the wumpus. A necessary precondition for attacking the wumpus is to deduce that it can try to kill and it should try to do so. Can try to kill the wumpus only if it's on a safe cell, it perceives stench and it's with orientation facing the cell where the wumpus possibly is. 
Should try to kill can be derived if it's known that it can try to kill the wumpus and none of the preconditions for don't shoot are known to be true. These preconditions for not shooting include: the arrow is not available, the wumpus is in a cell with a pit, the wumpus is already dead and the gold is already grabbed. 

\paragraph{Escape} The last available mode is \textit{escape}, in which the agent is if it's not in any of the other three modes. The agent is in this mode after grabbing the gold or after not being able to explore any other cells and leaves the cave empty handed.

%TODO Describe the modes that we extracted from the gameplay and what are the conditions that make the agent switch modes.


%TODO Describe the high level approach


\section{Implementation}
%TODO Short section where we describe the system, referring to the appendix (see below)
%TODO as well as that we used DLV.

%TODO Generate and include the Dependency Graph

%TODO Autopilot (if it works at some point)

%TODO Refer to usage file for actually running the system.

\section{Evaluation}

%TODO mention that we used randomly generated instances:

\begin{tabular}{ccc}
$n$ & $N_n$ \\
4 & 120 \\
5 &  20 \\
6 &  20 \\
7 &  20 \\
8 &  20 \\
\end{tabular}

%TODO maybe more instances?

%TODO We implemented an agent that solves the instances with perfect information to compare against.

%\input{sections/introduction}
%\input{sections/installation}
%\input{sections/strategy}
%\input{sections/evaluation}

%TODO Appendix: ASP Lite rendered as TeX from Markdown.

\end{document}
