\documentclass{llncs}

% A. Objectives
%    1. You should apply one of the techniques studied in the course to
%       solve this problem.
%    2. Devise and perform an empirical evaluation of your system.
%    3. Report your work.
%    4. All your documentation and source code should be available on your GitLab
%       project repository, as well as tasks and milestones. This will be part of
%       the evaluation.
%
% B. Deliverables
%    1. Progress report (by the end of May) describing
%     - selected approach and
%     - general project work plan
%     - group presentation of the report
%    2. Project report
%     - description of the problem
%     - updated material from the progress report
%     - description of your approach
%     - description of the software: installation, requirements and usage notes
%     - empirical evaluation
%    3. Software
%     - application and required libraries/software
%     - brief installation notes (README file)
%    4. Final Presentation
%     - description of your approach
%     - strengths and weaknesses
%     - empirical evaluation
%     - contribution of team members
%
% C. Timeline
%    1. 2018-05-30 Progress report and presentation
%    2. 2018-06-18 Software deliverable and final report
%    3. 2018-06-22 Final Presentation and Demo

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{geometry}
\geometry{
  a4paper,
  textwidth=16cm,  % llncs has 12.2cm
  textheight=25cm, % llncs has 19.3cm
  heightrounded,
  hratio=1:1,
  vratio=2:3,
}

\usepackage[english]{babel}

\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{csquotes}
\usepackage{multicol}
\usepackage{rotating}

\bibliographystyle{splncs03}

% In the appendix:
%\usepackage{longtable}
\usepackage{booktabs}

\usepackage{tikz,comment}
\usetikzlibrary{shapes.multipart,positioning,backgrounds}



\pagestyle{plain}

\newcommand{\htw}{\emph{Hunt the Wumpus }}

\title{Hakuna Matata: A Logic-Based Agent for the \htw Game}
\subtitle{Project Report}
\author{Team White\\[2mm]Filippo~De~Bortoli \and Aneta~Koleva \and Lorenz~Leutgeb}
\institute{Free University of Bozen-Bolzano\\[3mm] \texttt{\{\href{mailto:filippo.debortoli@stud-inf.unibz.it}{filippo.debortoli},\href{mailto:aneta.koleva@stud-inf.unibz.it}{aneta.koleva},\href{mailto:lorenz.leutgeb@stud-inf.unibz.it}{lorenz.leutgeb}\}\newline @stud-inf.unibz.it}}

\begin{document}

\maketitle
\thispagestyle{plain}

\begin{abstract}
  The assigned task is to develop an intelligent agent that plays the \htw game, by using a logic-based approach in its implementation.
  In order to complete a run of the game, this agent has to be able to face several challenges, like the incompleteness of the available information about the state of the world or the search for the best strategy to employ.
  The chosen approach is to develop a hybrid agent that relies on an ASP core to actuate its strategy and on graph-theory techniques to obtain additional insights on how to proceed in the exploration of a dungeon.
  To assess the performance of our agent, we implemented an omniscient agent that obtains an optimal score for a given dungeon and we ranked our agent against it.
  In this report, we introduce our solution to this task, by detailing the architecture of the agent and describing the chosen strategy, the heuristics and the obtained results.
\end{abstract}

\section{Problem Statement}
%TODO Define what \htw is, all its rules and constraints.
%TODO Mention that it is also an example in the standard textbook AIMA and thus suited as an exercise in logic-based AI.

\htw is a single player computer game, first released in 1975.
It is best known as a toy-problem in the field of Artificial Intelligence and has been thoroughly analysed by Russell and Norvig in~\cite{book:aima}, where it has been used to introduce the reader to a logic-based approach to \emph{Knowledge Representation} (KR). 

The game is played in the wumpus world(a cave) which is represented as a grid (default size 4x4) and in this world there are few challenges for the player. Each cell on the grid is a room which is connected by passageways with its orthogonally adjacent cell and in one of these cells there is wumpus, a beast that eats the player if he enters the room. The player has only one arrow, that's one opportunity for shooting the wumpus. In addition, some of the rooms are bottomless pits and if the player wanders in these rooms it will stay trapped. The main goal of the player is while facing these challenges, to find the hidden gold and leave the cave alive. At the beginning of the game, the player is always positioned on cell [1,1], facing to the right and has 0 points. From here it can use three moves : \textit{Forward, TurnLeft, TurnRight} for discovering its environment and three actions \textit{Shoot, Grab} and \textit{ Climb} for shooting the arrow, grabbing the gold and climbing out of the cave respectively. For each of the moves and actions the player loses 1 point and 10 points when using the arrow. When eaten by the wumpus or trapped in pit, loses 1000 points, and for climbing out of the cave with the gold gains 1000 points. Whenever the player goes to a new cell, it has five sensors that give information about:
\begin{description}
	\item [$\bullet$] Stench - whether the Wumpus is in adjacent cell 
	\item [$\bullet$] Breeze - whether there is a pit in adjacent cell	
	\item [$\bullet$] Glitter - when the gold is in the current cell
	\item [$\bullet$] Bump - whether the player has hit a border
	\item [$\bullet$] Scream- whether the Wumpus is hit by the arrow 
\end{description}
The locations of the gold and the wumpus are chosen randomly with uniform distribution in each cell other then the start. Additionally each cell can be a pit with probability 0.2.

In~\cite{book:aima}, the environment which represents the Wumpus World is is described as discrete, static, single-agent and partly-observable. For an agent in such environment the main challenge is its initial ignorance of the configuration of the world and using logical reasoning can be helpful for solving this. 

\section{Approach}
% This should be a high-level section that does not really talk too much
% about code (for that we have the "Implementation" section), but instead
% about the general approach.

In this section, we describe the ideas and the concepts that underlie our approach to the assigned task.
In particular, we single out those aspects that are relevant to the understanding of the behaviour that the Hakuna agent shows during a run of the game.

For the purpose of this project, we decided to implement a logic-based agent, that plays \htw employing both Answer Set Programming (ASP) and suitable search techniques --- borrowed from graph theory --- to explore the search space and find an optimal strategy to finish the game with the maximum score.

\subsection{ASP and World Knowledge}

The environment in which the agent is playing is \emph{discrete} and \emph{static}, since the wumpus, the gold and the pits do not move throughout the dungeon.
Therefore, the knowledge inferred by the agent at each point in time can be accumulated to circumscribe the search space in further moments in time.
Initially, the agent's \emph{knowledge base} (KB) is populated with basic geometric knowledge (e.g. relation between directions), what is percepted in its initial position and what are the known world sizes.

\paragraph{Incomplete knowledge.} One of the challenges of \htw is that a non-omniscient player starts the game with an incomplete knowledge of the world.
By exploring the dungeon and perceiving what is in each new explored room, an agent can obtain additional insights about the state of the world and reshape its strategy according to it.
As we want to be able to model non-monotonic reasoning --- if a room, previously thought to contain a pit, turns out to be safe, the agent should be able to infer this --- and to generalise statements by writing non-ground schematas, our system of choice is Answer Set Programming, which allows to model the problem in a logic fashion and achieves non-monotonic reasoning through \emph{closed-world assumption} (CWA).
In particular, the DLV solver~\cite{DLV-system} has been embedded in the architecture of the agent, to be called at every point in time to infer the additional knowledge obtained by the agent, after grounding its KB.
This approach allows the agent to correctly derive what is logically right from it's knowledge base. Moreover DLV is able to process incomplete knowledge which the agent has while overcoming its initial ignorance with logical reasoning.

\paragraph{Safety.} As the Hakuna agents tries to maximise its score by minimising its death chances, the need of a concept of \emph{safety} arises.
Namely, the agent moves towards some room if it is not aware of any danger lying in it (this is an application example of CWA) and marks as certainly \emph{safe} each room that he enters without dying.
This, together with the other perceived information, allows the agent to ``draw'' an internal representation of the world that will progressively allow it to move further or search for alternative exploratory routes.

\paragraph{Size of the world.} The agent proceeds by assuming that the world has a certain size, initially set to $1 \times 1$.
Every time the agent succeeds to move to a room which coordinates exceed the assumed size of the world, for example $N \times N$, the KB is updated to assume that the world has size $N+1 \times N+1$.
Otherwise, if a \emph{bump} is percepted, it infers the real size of the world and this will not be modified afterwards.

\paragraph{Dangers.} The agent's policy for dangers is the following:
\begin{itemize}
	\item If a room signalling a nearby danger is entered, turn backwards and explore the next \emph{safe} and unexplored room. A signal can be a perceived \emph{stench} or a \emph{breeze}.
	\item If the location of two stenches lying on a same axis is known, the wumpus is evinced to lie between them.
	\item If the location of two stenches lying on a same diagonal is known and one of the common neighbours is known to be safe, the other neighbouring room is inferred to contain the wumpus.
	\item If a breeze is found, all the unexplored neighbours are marked as rooms possibly containing a pit.
	\item If a room without breezes is found nearby one marked as a possible pit, the KB is updated to state that such a room is instead not containing any pit. 
\end{itemize}

% maybe mention that we can write strong constraints, not sure if still have that

\subsection{$A^{\star}$ Search and World Exploration}

For better exploration of the world, we build a graph that represents reachability (with cost) for all cells. Then we use \emph{Manhattan distance}~\cite{Manhattan} as a cost function for calculating the cost for moving from a cell to a cell. We also consider the rotation cost  when the agent reasons about the number of moves it needs to make in order to move from a cell to another cell. To calculate this cost, first the cost of all turns on the way from current cell to a destination cell is calculated and to this is added the cost of departing the current cell (whether the agent needs to turn before leaving). For calculating the minimal cost of reaching the destination cell we use \textit{A* search algorithm} : \(f(n) = g(n) + h(n)\). \
In order to efficiently use this algorithm next and goal cell must be known. 
First the goal cell is calculated and based on this result, the next cell is decided.  The choice of a goal cell depends on the current mode of the agent which are explained below. If it's in mode \textit{explore}, goal is a reachable cell which is safe and hasn't been explored yet. If the agent's mode is \textit{kill}, then the goal is a cell which is safe and from which the wumpus can be shot.   
In our program \(g(n)\) represents the cost of the path from the current cell to the next cell \(n\), and \(h(n)\) represents the heuristic estimated cost of the cheapest path from cell \(n\) to the goal cell. 

%TODO How does our agent explore the world (A*-search)
%not sure if here should be explained the purpose of pathTurnCost,
%departureTurnCost and rotCost or leave that for implementation

\subsection{Different modes}
In order to simplify the implementation of the agent and the way it choses its next action we introduce four different modes of playing in which the agent can be at any time. This helps to abstract and in different modes enable and disable different possible actions. It also made it easier for developing the code. 
While playing, our agent can be in exactly one from four available modes. 
\paragraph{Explore} The agent is in this mode until it discovers the gold or there are more cells which should be explored. These are cells which are known to be reachable, safe and not yet explored. 

\paragraph{Grab} Once the agent is in the cell where can perceive glitter, its next action is to grab the gold and in this moment is in mode \textit{grab}. 

\paragraph{Kill} In order for the agent to deduce that is in mode \textit{kill} few conditions need to be satisfied. First it should not be in mode grab or explore and the gold is still not grabbed. Next it should be able to attack the wumpus. A necessary precondition for attacking the wumpus is to deduce that it can try to kill and it should try to do so. Can try to kill the wumpus only if it's on a safe cell, it perceives stench and it's with orientation facing the cell where the wumpus possibly is. 
Should try to kill can be derived if it's known that it can try to kill the wumpus and none of the preconditions for don't shoot are known to be true. These preconditions for not shooting include: the arrow is not available, the wumpus is in a cell with a pit, the wumpus is already dead and the gold is already grabbed. 

\paragraph{Escape} The last available mode is \textit{escape}, in which the agent is if it's not in any of the other three modes. The agent is in this mode after grabbing the gold or after not being able to explore any other cells and leaves the cave empty handed.

%TODO Describe the modes that we extracted from the gameplay and what are the conditions that make the agent switch modes.

%TODO Describe the high level approach

\begin{center}
\begin{tikzpicture}[roundnode/.style={circle, draw=black!60, very thick,minimum size=4mm}]
	\begin{scope}
	    \node (n11) {$(1, 1)$};
		\node[roundnode] (u11) [below=5mm of n11] {$u$};
		\node[roundnode] (l11) [below left=10mm of u11] {$l$};
		\node[roundnode] (r11) [below right=10mm of u11] {$r$};
		\node[roundnode] (d11) [below right=10mm of l11] {$d$};
		\draw [<->] (u11) -> (l11);
		\draw [<->] (u11) -> (r11);
		\draw [<->] (d11) -> (l11);
		\draw [<->] (d11) -> (r11);
	\end{scope}

	\begin{scope}[xshift=5cm]
	    \node (n21) {$(2, 1)$};
		\node[roundnode] (u21) [below=5mm of n21] {$u$};
		\node[roundnode] (l21) [below left=10mm of u21] {$l$};
		\node[roundnode] (r21) [below right=10mm of u21] {$r$};
		\node[roundnode] (d21) [below right=10mm of l21] {$d$};
		\draw [<->] (u21) -> (l21);
		\draw [<->] (u21) -> (r21);
		\draw [<->] (d21) -> (l21);
		\draw [<->] (d21) -> (r21);
	\end{scope}

	\begin{scope}[yshift=5cm]
	    \node (n12) {$(1, 2)$};
		\node[roundnode] (u12) [below=5mm of n12] {$u$};
		\node[roundnode] (l12) [below left=10mm of u12] {$l$};
		\node[roundnode] (r12) [below right=10mm of u12] {$r$};
		\node[roundnode] (d12) [below right=10mm of l12] {$d$};
		\draw [<->] (u12) -> (l12);
		\draw [<->] (u12) -> (r12);
		\draw [<->] (d12) -> (l12);
		\draw [<->] (d12) -> (r12);
	\end{scope}

	\begin{scope}[yshift=5cm,xshift=5cm]
	    \node (n22) {$(2, 2)$};
		\node[roundnode] (u22) [below=5mm of n22] {$u$};
		\node[roundnode] (l22) [below left=10mm of u22] {$l$};
		\node[roundnode] (r22) [below right=10mm of u22] {$r$};
		\node[roundnode] (d22) [below right=10mm of l22] {$d$};
		\draw [<->] (u22) -> (l22);
		\draw [<->] (u22) -> (r22);
		\draw [<->] (d22) -> (l22);
		\draw [<->] (d22) -> (r22);
	\end{scope}

	\path [->] (r11) edge [bend left] (r21);
	\path [->] (l21) edge [bend left] (l11);
	\path [->] (u11) edge [bend left] (u12);
	\path [->] (d12) edge [bend left] (d11);
	\path [->] (u21) edge [bend left] (u22);
	\path [->] (d22) edge [bend left] (d21);
	\path [->] (r12) edge [bend left] (r22);
	\path [->] (l22) edge [bend left] (l12);

	\begin{pgfonlayer}{background}
		\filldraw[line width=4mm,join=round,black!5]
			(n11.north -| r11.east) rectangle (d11.south -| l11.west)
			(n21.north -| r21.east) rectangle (d21.south -| l21.west)
			(n12.north -| r12.east) rectangle (d12.south -| l12.west)
			(n22.north -| r22.east) rectangle (d22.south -| l22.west);
	\end{pgfonlayer}
\end{tikzpicture}
\end{center}

\section{Implementation}
%TODO Short section where we describe the system, referring to the appendix (see below)
%TODO as well as that we used DLV.
%TODO Generate and include the Dependency Graph
%TODO Autopilot (if it works at some point)
%TODO Refer to usage file for actually running the system.

In this section, we briefly describe how the agent described in the previous section was implemented. Note, however that for the implementation in its full detail we refer to Appendix \ref{hunt-the-wumpus}. Further, for the Python code that hosts the ASP based implementation and usage notes we refer to the project repository.

The Python host keeps state in memory as the game progresses. This includes perceptions for all visited rooms, from which room and in which orientation the agent has shot the arrow (if applicable), whether the wumpus is dead or alive, and whether the agent has ever performed the \emph{grab} action. All this information is considered the \emph{memory} of the agent, and encoded as facts every time the logic program is invoked for the purpose of reasoning about the next action.

\begin{figure}
\begin{tikzpicture}
% py and sim should be inside pyr
% mem should be inside py
% asp should be inside dlv

\node[fill=blue!30,text depth = 3cm,minimum width=3cm,font=\Large] (pyr) {Python Runtime};
\node (sim) at (pyr.center) {Wumpus World Simulator};
\node (py) at (pyr.south) {Python Implementation};
\node (mem) at (py.south) {Memory};

\node (dlv) {DLV};
\node (asp) {ASP Implementation};

\draw [->] (py) -> (asp) node [midway, below] {Facts};
\draw [->] (asp) -> (py) node [midway, below] {Answer Set};

\draw [->] (py) -> (sim) node [midway, below] {Action};
\draw [->] (sim) -> (py) node [midway, below] {Perception};
\end{tikzpicture}
\end{figure}

%\begin{sidewaysfigure}[ht]
%\includegraphics[width=1\textwidth]{dep}
%\caption[Dependency Graph of the Logic Program]{Dependency Graph of the Logic Program. }
%\end{sidewaysfigure}

\section{Evaluation}

In this section, we explain how the empirical evaluation of our agent has been carried out.
In particular, we describe which experiments our agent has been tested with, which parameters have been collected and how its performance has been assessed.
To produce a satisfying evaluation, we generated a testing suite and, in order to obtain a reliable reference, we built an omniscient agent.

\subsection{Testing Suite}

In order to collect the results of our agent, we devised a testing suite, composed by a batch of dungeons, randomly generated by the Wumpus World Simulator that was made available as part of the assignment.
Each entry of this suite, bundled together with our implementation of the agent, has the form \emph{world-<size>-<seed>}, where the \emph{seed} allows to reproduce the creation of the selected dungeon.
In Table~\ref{tbl:test}, the composition of the testing suite is outlined.
%TODO mention that we used randomly generated instances:

\begin{table}[t]
	\label{tbl:test}
	\centering
	\begin{tabular}{ccc}
	\toprule
	Worlds size & Number of instances \\
	\midrule
	4 & 120 \\
	5 &  20 \\
	6 &  20 \\
	7 &  20 \\
	8 &  20 \\
	\bottomrule\\
	\end{tabular}
	\caption{Composition of the testing suite used to assess the performances of Hakuna.}
\end{table}

Each world has been generated by taking into account the rules of \htw: indeed, each instance has a squared shape, it contains only one wumpus, one unit of gold and it may contain several pits, sparse through the dungeon.

%TODO maybe more instances?

\subsection{An omniscient agent}

In order to assess the performance of our Hakuna agent, we built another agent, whose score has then been referenced in evaluating our results.

The particularity of this other agent is \emph{omnisciency}: indeed, our assumption is that it has a perfect knowledge of the world: the location of the dangers and the location of the gold.
In this setting, the search for the optimal solution can be reduced to the computation of the shortest path from the initial point over an \emph{action graph} built in the following way:
\begin{itemize}
	\item Each node is a configuration $(X,Y,O)$ that the agent can assume.
	\item Two configurations are linked by an edge if one can be reached by the other.
	\item The weight of each edge is $1$ if the target is not a configuration in the same position as the Wumpus's, $10$ otherwise; this reflects the need to kill the Wumpus in order to pass through it.
\end{itemize}
A shortest path over this graph reflects the shortest path in the dungeon from a configuration to another.
Here, the cost function is the same that has been previously employed.

Then, the perfect agent behaves as follows: if the gold is unreachable, thus it lies in a pit, it immediately climbs; otherwise, he takes the shortest path to the cell containing the gold, grabs it and comes back to the initial position from the same path, to finally climb.

\subsection{Performance Assessment}

For each instance, a run of the omniscient agent and one of the Hakuna agent have been recorded and their scores collected for comparison.
Being ours a pure logic-based approach, the score obtained by both agents on an instance can be exactly reproduced, given the agent and the instance; this would not be the case, if probabilistic reasoning was taken into account.
From the collected data, the gap between the results scored by the two agents in each instance has been computed, and the sample mean and standard deviation have been computed.

After data collection, we investigated those instances where the the perfect agent outperformed Kakuna, to understand the possible causes and search for plausible improvements.
What we have found out can be summarised as the following:
\begin{itemize}
	\item Hakuna performed similarly to the agent in those instances where the gold was reachable by just exploring the dungeon and in those where killing the Wumpus led to the discovery of a safe path to the gold.
	\item On the other hand, Hakuna was outperformed in those instances where the phenomenon of \emph{breeze walls} happened: the location of the breezes brought the agent to infer a disposition of possible pits that blocked its way to the gold, even though there were no pits between it and the reward.
	\item On instances where gold was unreachable, the agent lost on average a small amount of points before concluding that the search was useless and climbing back to the exit.
\end{itemize}

% TODO: talking about runtime? Influence of the autopilot?

\newpage

\appendix
\footnotesize

\begin{multicols}{2}
\include{appendix}
\end{multicols}

\bibliography{ref}

\end{document}
